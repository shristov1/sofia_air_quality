{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from download_climate_data import download_data\n",
    "import os\n",
    "import datetime\n",
    "import weathercom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are only interested in sensors with the following parameters: (sensor_name = sds011, sensor_id = 6127) and (sensor_name = bme280, sensor_id = 6128)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def part_day(x):\n",
    "    \"\"\" Returns part of day based on the timestamp hour \"\"\"\n",
    "    x = x.hour\n",
    "    if (x > 4) and (x <= 8):\n",
    "        return 1\n",
    "    elif (x > 8) and (x <= 12):\n",
    "        return 2\n",
    "    elif (x > 12) and (x <= 14):\n",
    "        return 3\n",
    "    elif (x > 14) and (x <= 18):\n",
    "        return 4\n",
    "    elif (x > 18) and (x <= 22):\n",
    "        return 5\n",
    "    else:\n",
    "        return 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def season(x):\n",
    "    \"\"\"Returns season based on month\"\"\"\n",
    "    x = x.month\n",
    "    if (x > 3) and (x <= 6):\n",
    "        return 1\n",
    "    elif (x > 6) and (x <= 9):\n",
    "        return 2\n",
    "    elif (x > 9) and (x <= 11):\n",
    "        return 3\n",
    "    else:\n",
    "        return 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_workday(x):\n",
    "    \"\"\" Returns if day is workday\"\"\"\n",
    "    if x <= 4:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_print_plot(df, category: str, data_col1: str, data_col2: str) -> None:\n",
    "    \"\"\"Function which prints the mean of each category in a data column and plots the difference between the 2 datasets\n",
    "    \n",
    "    Parameters: \n",
    "    df: data frame\n",
    "    category: category name\n",
    "    data_col1: data to calculate mean on\n",
    "    data_col2: data to calculate mean on\n",
    "    \n",
    "    Returns: \n",
    "    None\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"P1 data stats: {df.groupby([category]).mean()[data_col1].sort_index()}\")\n",
    "    print('------------------------------------------------')\n",
    "    print(f\"P2 data stats: {df.groupby([category]).mean()[data_col2].sort_index()}\")\n",
    "    \n",
    "    plt.plot(df.groupby([category]).mean()[data_col1].sort_index(), label='P1')\n",
    "    plt.plot(df.groupby([category]).mean()[data_col2].sort_index(), label='P2')\n",
    "    plt.title(f'Mean of {data_col1} and {data_col2} per {category} category')\n",
    "    plt.legend()\n",
    "    plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_p1_high(x):\n",
    "    if x > 35:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_holiday(x):\n",
    "    \"\"\" Returns if it is holiday if date is 3 days around a holiday\"\"\"\n",
    "    for holiday in HOLIDAYS:\n",
    "        if (x >= holiday-datetime.timedelta(days=3)) and (x <= holiday + datetime.timedelta(days=3)):\n",
    "            return 1\n",
    "        else:\n",
    "            return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, we are going to create a list with all public holidays:  \n",
    "Date\tHoliday\tOfficial Name  \n",
    "1 January\tNew Year's Day   \n",
    "3 March\tLiberation Day  \n",
    "1 May\tInternational Workers' Day  \n",
    "6 May\tSaint George's Day  \n",
    "24 May\tBulgarian Education and Culture and Slavonic Literature Day  \n",
    "6 September\tUnification Day  \n",
    "22 September\tIndependence Day  \n",
    "24 December\tChristmas Eve  \n",
    "25 & 26 December\tChristmas Day  \n",
    "Moveable\tOrthodox Good Friday, Holy Saturday & Easter  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Automatically take it from G calendar API\n",
    "HOLIDAYS = [datetime.date(2020,4,19), datetime.date(2021,1,1), datetime.date(2021,3,3),datetime.date(2020,5,1),\n",
    "            datetime.date(2020,5,6),datetime.date(2020,5,24),datetime.date(2020,9,6),\n",
    "            datetime.date(2020,9,22),datetime.date(2020,12,24),datetime.date(2020,12,25),datetime.date(2020,12,26)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "START_DATE = datetime.date(2020,4,1)   # start time for the analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data download now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading: 2020-04-01\n",
      "Downloading: 2020-04-02\n",
      "Downloading: 2020-04-03\n",
      "Downloading: 2020-04-04\n",
      "Downloading: 2020-04-05\n",
      "Downloading: 2020-04-06\n",
      "Downloading: 2020-04-07\n",
      "Downloading: 2020-04-08\n",
      "Downloading: 2020-04-09\n",
      "Downloading: 2020-04-10\n",
      "Downloading: 2020-04-11\n",
      "Downloading: 2020-04-12\n",
      "Downloading: 2020-04-13\n",
      "Downloading: 2020-04-14\n",
      "Downloading: 2020-04-15\n",
      "Downloading: 2020-04-16\n",
      "Downloading: 2020-04-17\n",
      "Downloading: 2020-04-18\n",
      "Downloading: 2020-04-19\n",
      "Downloading: 2020-04-20\n",
      "Downloading: 2020-04-21\n",
      "Downloading: 2020-04-22\n",
      "Downloading: 2020-04-23\n",
      "Downloading: 2020-04-24\n",
      "Downloading: 2020-04-25\n",
      "Downloading: 2020-04-26\n",
      "Downloading: 2020-04-27\n",
      "Downloading: 2020-04-28\n",
      "Downloading: 2020-04-29\n",
      "Downloading: 2020-04-30\n",
      "Downloading: 2020-05-01\n",
      "Downloading: 2020-05-02\n",
      "Downloading: 2020-05-03\n",
      "Downloading: 2020-05-04\n",
      "Downloading: 2020-05-05\n",
      "Downloading: 2020-05-06\n",
      "Downloading: 2020-05-07\n",
      "Downloading: 2020-05-08\n",
      "Downloading: 2020-05-09\n",
      "Downloading: 2020-05-10\n",
      "Downloading: 2020-05-11\n",
      "Downloading: 2020-05-12\n",
      "Downloading: 2020-05-13\n",
      "Downloading: 2020-05-14\n",
      "Downloading: 2020-05-15\n",
      "Downloading: 2020-05-16\n",
      "Downloading: 2020-05-17\n",
      "Downloading: 2020-05-18\n",
      "Downloading: 2020-05-19\n",
      "Downloading: 2020-05-20\n",
      "Downloading: 2020-05-21\n",
      "Downloading: 2020-05-22\n",
      "Downloading: 2020-05-23\n",
      "Downloading: 2020-05-24\n",
      "Downloading: 2020-05-25\n",
      "Downloading: 2020-05-26\n",
      "Downloading: 2020-05-27\n",
      "Downloading: 2020-05-28\n",
      "Downloading: 2020-05-29\n",
      "Downloading: 2020-05-30\n",
      "Downloading: 2020-05-31\n",
      "Downloading: 2020-06-01\n",
      "Downloading: 2020-06-02\n",
      "Downloading: 2020-06-03\n",
      "Downloading: 2020-06-04\n",
      "Downloading: 2020-06-05\n",
      "Downloading: 2020-06-06\n",
      "Downloading: 2020-06-07\n",
      "Downloading: 2020-06-08\n",
      "Downloading: 2020-06-09\n",
      "Downloading: 2020-06-10\n",
      "Downloading: 2020-06-11\n",
      "Downloading: 2020-06-12\n",
      "Downloading: 2020-06-13\n",
      "Downloading: 2020-06-14\n",
      "Downloading: 2020-06-15\n",
      "Downloading: 2020-06-16\n",
      "Downloading: 2020-06-17\n",
      "Downloading: 2020-06-18\n",
      "Downloading: 2020-06-19\n",
      "Downloading: 2020-06-20\n",
      "Downloading: 2020-06-21\n"
     ]
    }
   ],
   "source": [
    "download_data(sensor_name='sds011', sensor_id=6127)\n",
    "download_data(sensor_name='bme280', sensor_id=6128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We have all the data, let us now load the data in dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list = os.listdir('./data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_list = set([file.split('_')[0] for file in file_list]) # get unique dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for date in date_list:\n",
    "    for file in file_list:\n",
    "        if file.find(date) != -1:\n",
    "            if file.find('bme280') != -1:\n",
    "                df_temp_1 = pd.read_csv('./data/'+file, sep=';')\n",
    "                df_temp_1.timestamp = pd.to_datetime(df_temp_1.timestamp, errors='ignore', infer_datetime_format=True)\n",
    "            elif file.find('sds011') != -1:\n",
    "                df_temp_2 = pd.read_csv('./data/'+file, sep=';')\n",
    "                df_temp_2.timestamp = pd.to_datetime(df_temp_2.timestamp, errors='ignore', infer_datetime_format=True)\n",
    "            \n",
    "        df_1 = pd.merge_asof(df_temp_1, df_temp_2, on='timestamp', direction='nearest', tolerance=datetime.timedelta(seconds=20), allow_exact_matches=False)\n",
    "        df_1.drop(['altitude', 'pressure', 'durP2', 'ratioP2', 'durP1', 'ratioP1', \"ratioP2\",\n",
    "                  'sensor_id_x', 'sensor_type_x', 'location_x', 'lat_x', 'lon_x', 'pressure_sealevel',\n",
    "                  'sensor_id_y', 'sensor_type_y', 'location_y', 'lat_y','lon_y'], axis=1, inplace=True);\n",
    "        df_1.dropna(inplace=True)\n",
    "    df = pd.concat([df, df_1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(inplace=True)\n",
    "df.drop('index', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['IsHoliday'] = df['timestamp'].apply(is_holiday) \n",
    "df['PartDay'] = df['timestamp'].apply(part_day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['WeekDay'] = df['timestamp'].dt.dayofweek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['IsWorking'] = df['WeekDay'].apply(is_workday)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Season'] = df['timestamp'].apply(season)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if the P1 and P2 values are higher in any part of the day or if it is a holiday."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_print_plot(df, category='IsHoliday', data_col1='P1', data_col2='P2')\n",
    "locs, ticks = plt.xticks()\n",
    "plt.xticks([locs[1], locs[-2]], ['Normal day', 'Holiday'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_print_plot(df, category='WeekDay', data_col1='P1', data_col2='P2')\n",
    "locs, ticks = plt.xticks()\n",
    "plt.xticks(locs, ['', 'Mon','Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun', ''])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_blah = df.loc[df['PartDay']==6]\n",
    "mean_print_plot(df_blah, category='Season', data_col1='P1', data_col2 = 'P2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_print_plot(df, category='PartDay', data_col1='P1', data_col2='P2')\n",
    "locs, ticks = plt.xticks()\n",
    "plt.xticks(locs, [' ','Early Morning', 'Morning', 'Noon', 'Afternoon', 'Evening', 'Night', ''])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_print_plot(df, category='Season', data_col1='P1', data_col2='P2')\n",
    "locs, ticks = plt.xticks()\n",
    "plt.xticks(locs[1:-1:2], ['Spring', 'Summer', 'Autumn', 'Winter'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### As we see there are correlations between the season, week day, time of day and holidays and the air quality. \n",
    "##### I will now check with a seaborn correlation plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(df.corr(), annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Strangly enough there seems to be a correlation also between the humidity and the air quality, but not that much with temperature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression\n",
    "##### I think that this problem may be best generalized with a random forest model. First I will start with a regressor, then I will use a classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['temperature', 'humidity', 'IsHoliday', 'WeekDay', 'Season']]\n",
    "y = df['P1']\n",
    "today = [12, 47, 0, 1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc_regr = StandardScaler()\n",
    "X_train = sc_regr.fit_transform(X_train)\n",
    "X_test = sc_regr.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "today = sc_regr.transform([today])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = RandomForestRegressor()\n",
    "regr_svm = SVR()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr.fit(X_train, y_train)\n",
    "regr_svm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr.predict(today)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr_svm.predict(today)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_svm = regr_svm.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regression ANN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_regr = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_regr.add(tf.keras.layers.Dense(units = 5, activation='relu'))\n",
    "ann_regr.add(tf.keras.layers.Dense(units = 8, activation='relu'))\n",
    "ann_regr.add(tf.keras.layers.Dense(units=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_regr.compile(optimizer='adam', loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_regr.fit(X, y, batch_size=64, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = ann_regr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_regr.predict(today)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Later training XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['HighP1'] = df['P1'].apply(is_p1_high)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now I will run a classification RF model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['HighP1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3)\n",
    "today = [1, 100, 0, 6, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.predict_proba([today])\n",
    "regr.predict([today])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.feature_importances_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results are not great - this may be due to overfitting of the clean air data as we have roughly 5 times more data for that case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_svc = SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "today = sc.transform([today])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_svc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_pred_svc = classifier_svc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred_svc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_svc.predict(today)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I will try with ANN regression/classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann.add(tf.keras.layers.Dense(units = 8, activation='relu'))\n",
    "ann.add(tf.keras.layers.Dense(units = 8, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann.fit(X_train, y_train, batch_size=64, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = ann.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann.predict(today)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = (y_pred > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = weathercom.getCityWeatherDetails(city='Sofia',queryType=\"ten-days-data\")\n",
    "df = pd.read_json(data)\n",
    "weather = pd.DataFrame()\n",
    "date = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather['Temperature'] = df['vt1dailyForecast']['day']['temperature']\n",
    "weather['Humidity'] = df['vt1dailyForecast']['day']['humidityPct']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date['Date'] = pd.to_datetime(df['vt1dailyForecast']['validDate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather['IsHoliday'] = date['Date'].apply(is_holiday)\n",
    "weather['Weekday'] = date['Date'].dt.dayofweek\n",
    "weather['Season'] = date['Date'].apply(season)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather = sc_regr.transform(weather)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_regr.predict(weather)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving the model so it can be reused"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(sc_regr, 'std_scaler.bin', compress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_regr.save('ann_regr_weather.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
